import os
import gymnasium as gym
import gymnasium_env
from gymnasium.wrappers import TimeLimit
from stable_baselines3 import SAC
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback
from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor

# å¯¼å…¥ä½ è‡ªå®šä¹‰çš„ Wrapper å’Œ Policy
from graph_obs_wrapper import PaddedGraphObsWrapper, PaddedActionWrapper
from masked_graph_policy import MaskedGraphSACPolicy

print(f"testing train graph ppo.py")
XML_FILE = "./gymnasium_env/envs/reacher_2j.xml"  # ä½¿ç”¨ä½ ä¿®æ”¹å¥½ç‰©ç†å‚æ•°çš„ XML
env_name = "gymnasium_env/Reacher2D-v0"
max_episode_steps = 100
total_timesteps = int(1e6)
seed = 0

def make_env(render_mode=None):
    def _init():
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä½ ç¡®ä¿åº•å±‚ _get_obs è¿”å›çš„æ˜¯ä¸€ä¸ªå®Œæ•´çš„å­—å…¸ï¼Œ
        # æˆ–è€…ç›´æ¥è®©ä½ çš„ Wrapper å¤„ç†åŸå§‹çš„ dictã€‚
        env = gym.make(env_name, xml_file=XML_FILE, render_mode=render_mode)
        env = TimeLimit(env, max_episode_steps=max_episode_steps)
        env = Monitor(env)
        env = PaddedGraphObsWrapper(env, max_joints=10) # åŒ…è£…ç¯å¢ƒï¼
        env = PaddedActionWrapper(env, max_joints=10, n_arm_joints=2)
        return env
    return _init

train_env = VecMonitor(DummyVecEnv([make_env(render_mode=None)]))
eval_env = VecMonitor(DummyVecEnv([make_env(render_mode=None)]))

tb_log = os.path.join("sb3_runs", env_name, f"sac_gnn_seed{seed}")

eval_callback = EvalCallback(
    eval_env,
    best_model_save_path=os.path.join("sb3_checkpoints", env_name, "best_sac_gnn"),
    log_path=os.path.join("sb3_eval_logs", env_name),
    eval_freq=10_000,
    n_eval_episodes=5,
    deterministic=True,
    render=False
)

ckpt_callback = CheckpointCallback(
    save_freq=100_000,
    save_path=os.path.join("sb3_checkpoints", env_name, "ckpt"),
    name_prefix="sac_gnn"
)

# ä½¿ç”¨ SAC è®­ç»ƒ Transformer ç­–ç•¥
model = SAC(
    policy=MaskedGraphSACPolicy,
    # policy = "MultiInputPolicy",
    env=train_env,
    learning_rate=3e-4,
    buffer_size=100_000,   # SAC ç»éªŒå›æ”¾æ± 
    batch_size=256,        # ğŸš€ å¢å¤§ Batch Size ä»¥ç¨³å®š Transformer çš„æ¢¯åº¦
    ent_coef="auto",       # è‡ªåŠ¨è°ƒèŠ‚ç†µï¼Œé¼“åŠ±æ¢ç´¢
    # target_entropy=-2.0,
    gamma=0.99,
    tau=0.005,
    tensorboard_log=tb_log,
    verbose=1,
    seed=seed,
)

print("å¼€å§‹ä½¿ç”¨ Transformer SAC è®­ç»ƒ...")
model.learn(
    total_timesteps=total_timesteps,
    callback=[eval_callback, ckpt_callback],
    tb_log_name="SAC_GNN"
)

model.save(os.path.join("sb3_checkpoints", env_name, "final_sac_gnn_model"))
train_env.close()
eval_env.close()
print("è®­ç»ƒå®Œæˆã€‚TensorBoard logdir:", tb_log)