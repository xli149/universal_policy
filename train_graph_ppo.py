import gymnasium as gym
import gymnasium_env
from stable_baselines3 import SAC
from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor
from graph_obs_wrapper import PaddedGraphObsWrapper
from masked_graph_policy import MaskedGraphSACPolicy # âœ… å¼•å…¥æ–°çš„ SAC Policy

def make_env(xml_file):
    def _init():
        env = gym.make("gymnasium_env/Reacher2D-v0", xml_file=xml_file)
        from gymnasium.wrappers import TimeLimit
        env = TimeLimit(env, max_episode_steps=50)
        env = PaddedGraphObsWrapper(env, max_joints=10)
        return env
    return _init

def train():
    XML_2J = "/Users/chrislee/Documents/mujoco_test/gymnasium_env/envs/reacher_2j.xml"
    
    # SAC é€šå¸¸å¯¹ç¯å¢ƒå¹¶è¡Œçš„ä¾èµ–æ²¡æœ‰ PPO é‚£ä¹ˆé‡ï¼Œå¼€ 4-8 ä¸ªå‡å¯
    venv = DummyVecEnv([make_env(XML_2J) for _ in range(8)])
    venv = VecMonitor(venv)

    model = SAC(
        policy=MaskedGraphSACPolicy,
        env=venv,
        learning_rate=3e-4,
        buffer_size=100000,     # âœ… SAC çµé­‚ï¼šç»éªŒå›æ”¾æ± 
        batch_size=256,
        ent_coef=0.02,        # âœ… SAC é­”æ³•ï¼šè®©å®ƒè‡ªå·±è°ƒæ¢ç´¢æ¬²æœ›ï¼
        gamma=0.99,
        tau=0.005,              # ç›®æ ‡ç½‘ç»œè½¯æ›´æ–°
        train_freq=1,           # æ¯èµ° 1 æ­¥å°±æ‹¿å›æ”¾æ± çš„æ•°æ®è®­ç»ƒ 1 æ¬¡
        gradient_steps=1,
        verbose=1,
        tensorboard_log="./sac_reacher_tensorboard/"
    )

    print("ğŸš€ Starting SAC Training...")
    model.learn(total_timesteps=500000, log_interval=4)
    model.save("./checkpoints/graph_reach_sac_final")
    print(f"Model saved to ./checkpoints/graph_reach_sac_final ")

if __name__ == "__main__":
    train()