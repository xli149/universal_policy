import os
import torch  # ğŸš€ æ–°å¢ï¼šç”¨äºæ£€æµ‹è®¾å¤‡
from typing import Callable  # ğŸš€ æ–°å¢ï¼šç”¨äºå®šä¹‰å­¦ä¹ ç‡è¡°å‡
import gymnasium as gym
import gymnasium_env
from gymnasium.wrappers import TimeLimit
from stable_baselines3 import SAC
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback
from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor

# å¯¼å…¥ä½ è‡ªå®šä¹‰çš„ Wrapper å’Œ Policy
from graph_obs_wrapper import PaddedGraphObsWrapper, PaddedActionWrapper
from masked_graph_policy import MaskedGraphSACPolicy

print(f"testing train graph ppo.py")
XML_FILE = "./gymnasium_env/envs/reacher_2j.xml"  
env_name = "gymnasium_env/Reacher2D-v0"
max_episode_steps = 100
total_timesteps = int(1e6)
seed = 0

# ==========================================
# ğŸš€ è¿›é˜¶æŠ€å·§ 1ï¼šè‡ªåŠ¨æ£€æµ‹è®¡ç®—è®¾å¤‡ (MPS/CUDA/CPU)
# ==========================================
if torch.backends.mps.is_available():
    device = "mps"
elif torch.cuda.is_available():
    device = "cuda"
else:
    device = "cpu"
print(f"\nğŸ”¥ å‡†å¤‡ä½¿ç”¨çš„è®¡ç®—è®¾å¤‡: {device.upper()}\n")

# ==========================================
# ğŸš€ è¿›é˜¶æŠ€å·§ 2ï¼šå®šä¹‰çº¿æ€§å­¦ä¹ ç‡è¡°å‡
# ==========================================
def linear_schedule(initial_value: float) -> Callable[[float], float]:
    def func(progress_remaining: float) -> float:
        # progress_remaining ä» 1.0 çº¿æ€§é™åˆ° 0.0
        return progress_remaining * initial_value
    return func

def make_env(render_mode=None):
    def _init():
        env = gym.make(env_name, xml_file=XML_FILE, render_mode=render_mode)
        env = TimeLimit(env, max_episode_steps=max_episode_steps)
        env = Monitor(env)
        
        # ğŸš€ ä¿®å¤éšæ‚£ï¼šPaddedGraphObsWrapper ä¹‹å‰æ¼æ‰äº† n_arm_joints=2ï¼Œå¿…é¡»åŠ ä¸Šï¼
        env = PaddedGraphObsWrapper(env, max_joints=10, n_arm_joints=2) 
        env = PaddedActionWrapper(env, max_joints=10, n_arm_joints=2)
        return env
    return _init

train_env = VecMonitor(DummyVecEnv([make_env(render_mode=None)]))
eval_env = VecMonitor(DummyVecEnv([make_env(render_mode=None)]))

tb_log = os.path.join("sb3_runs", env_name, f"sac_gnn_seed{seed}")

eval_callback = EvalCallback(
    eval_env,
    best_model_save_path=os.path.join("sb3_checkpoints", env_name, "best_sac_gnn"),
    log_path=os.path.join("sb3_eval_logs", env_name),
    eval_freq=10_000,
    n_eval_episodes=5,
    deterministic=True,
    render=False
)

ckpt_callback = CheckpointCallback(
    save_freq=100_000,
    save_path=os.path.join("sb3_checkpoints", env_name, "ckpt"),
    name_prefix="sac_gnn"
)

# ä½¿ç”¨ SAC è®­ç»ƒç­–ç•¥
model = SAC(
    policy=MaskedGraphSACPolicy,
    env=train_env,
    # ğŸš€ è¿›é˜¶æŠ€å·§åº”ç”¨ï¼šä½¿ç”¨å­¦ä¹ ç‡è¡°å‡ï¼Œä» 3e-4 å¹³æ»‘é™è‡³ 0ï¼Œä¾¿äºåæœŸé€¼è¿‘æé™ -3 åˆ†
    learning_rate=linear_schedule(3e-4),
    buffer_size=100_000,
    batch_size=256,        
    
    # ğŸš€ è¿›é˜¶æŠ€å·§ 3ï¼šå›ºå®šæ¢ç´¢ç³»æ•°ã€‚èˆå¼ƒ "auto"ï¼Œé˜²æ­¢ç†µè·Œåˆ° 0 å¯¼è‡´æ¨¡å‹æ‘†çƒ‚
    ent_coef=0.01,       
    
    gamma=0.99,
    tau=0.005,
    tensorboard_log=tb_log,
    verbose=1,
    seed=seed,
    
    # ğŸš€ æŒ‡å®šä½¿ç”¨çš„ç¡¬ä»¶è®¾å¤‡
    device=device,
)

print("å¼€å§‹ä½¿ç”¨ GCN SAC è®­ç»ƒ...")
model.learn(
    total_timesteps=total_timesteps,
    callback=[eval_callback, ckpt_callback],
    tb_log_name="SAC_GNN"
)

model.save(os.path.join("sb3_checkpoints", env_name, "final_sac_gnn_model"))
train_env.close()
eval_env.close()
print("è®­ç»ƒå®Œæˆã€‚TensorBoard logdir:", tb_log)