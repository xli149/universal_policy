import os
import torch  
from typing import Callable  
import gymnasium as gym
import gymnasium_env
from gymnasium.wrappers import TimeLimit
from stable_baselines3 import SAC
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.callbacks import EvalCallback
from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor

# å¯¼å…¥ä½ è‡ªå®šä¹‰çš„ Wrapper å’Œ Policy
from graph_obs_wrapper import PaddedGraphObsWrapper, PaddedActionWrapper
from masked_graph_policy import MaskedGraphSACPolicy

print("testing train graph ppo.py")

# ==========================================
# âš™ï¸ æ ¸å¿ƒé…ç½®åŒº (åˆ‡æ¢åœºæ™¯æ—¶ï¼Œåªéœ€ä¿®æ”¹è¿™ä¸¤è¡Œï¼)
# ==========================================
XML_FILE = "./gymnasium_env/envs/reacher_3j.xml"  
N_ARM_JOINTS = 3  # ğŸš€ åŠ¡å¿…ä¸ XML æ–‡ä»¶é‡Œçš„çœŸå®æ‰‹è‡‚å…³èŠ‚æ•°ä¿æŒä¸€è‡´ï¼

env_name = "gymnasium_env/Reacher2D-v0"
max_episode_steps = 100
total_timesteps = int(1e6)
seed = 0

# ğŸš€ è‡ªåŠ¨æå–åœºæ™¯åç§° (æ¯”å¦‚æå–å‡º "reacher_2j")
scenario_name = os.path.splitext(os.path.basename(XML_FILE))[0]

# ğŸ“ æç®€çš„ç›®å½•è·¯å¾„è®¾è®¡
tb_log_dir = f"./tb_logs/{scenario_name}"
ckpt_dir = f"./checkpoints/{scenario_name}"

print(f"\nğŸ“ å½“å‰å®éªŒåœºæ™¯: {scenario_name}, çœŸå®å…³èŠ‚æ•°: {N_ARM_JOINTS}")

# ==========================================
# è‡ªåŠ¨æ£€æµ‹è®¡ç®—è®¾å¤‡ (MPS/CUDA/CPU)
# ==========================================
if torch.backends.mps.is_available():
    device = "mps"
elif torch.cuda.is_available():
    device = "cuda"
else:
    device = "cpu"
print(f"ğŸ”¥ å‡†å¤‡ä½¿ç”¨çš„è®¡ç®—è®¾å¤‡: {device.upper()}\n")

# å®šä¹‰çº¿æ€§å­¦ä¹ ç‡è¡°å‡
def linear_schedule(initial_value: float) -> Callable[[float], float]:
    def func(progress_remaining: float) -> float:
        return progress_remaining * initial_value
    return func

def make_env(render_mode=None):
    def _init():
        env = gym.make(env_name, xml_file=XML_FILE, render_mode=render_mode)
        env = TimeLimit(env, max_episode_steps=max_episode_steps)
        env = Monitor(env)
        
        # ğŸš€ åŠ¨æ€ä¼ å…¥çœŸå®å…³èŠ‚æ•°ï¼Œæ‹’ç»ç¡¬ç¼–ç 
        env = PaddedGraphObsWrapper(env, max_joints=10, n_arm_joints=N_ARM_JOINTS) 
        env = PaddedActionWrapper(env, max_joints=10, n_arm_joints=N_ARM_JOINTS)
        return env
    return _init

train_env = VecMonitor(DummyVecEnv([make_env(render_mode=None)]))
eval_env = VecMonitor(DummyVecEnv([make_env(render_mode=None)]))

# ==========================================
# è®¾ç½®å›è°ƒå‡½æ•°ï¼šåªä¿ç•™æœ€æœ‰ç”¨çš„æœ€é«˜åˆ†æ¨¡å‹å­˜æ¡£
# ==========================================
eval_callback = EvalCallback(
    eval_env,
    best_model_save_path=ckpt_dir,     # ğŸš€ æœ€å¥½çš„æ¨¡å‹ç›´æ¥å­˜åˆ°å¯¹åº”çš„åœºæ™¯æ–‡ä»¶å¤¹é‡Œ
    log_path=ckpt_dir,                 # è¯„ä¼°çš„ numpy æˆç»©å•ä¹Ÿå­˜åœ¨è¿™é‡Œ
    eval_freq=10_000,
    n_eval_episodes=5,
    deterministic=True,
    render=False
)

# ä½¿ç”¨ SAC è®­ç»ƒç­–ç•¥
model = SAC(
    policy=MaskedGraphSACPolicy,
    env=train_env,
    learning_rate=linear_schedule(3e-4),
    buffer_size=100_000,
    batch_size=256,        
    ent_coef=0.01,       
    gamma=0.99,
    tau=0.005,
    tensorboard_log=tb_log_dir,        # ğŸš€ æŒ‡å‘æç®€çš„æ—¥å¿—æ–‡ä»¶å¤¹
    verbose=1,
    seed=seed,
    device=device,
)

print(f"å¼€å§‹ä½¿ç”¨ GCN SAC è®­ç»ƒ {scenario_name} ...")
model.learn(
    total_timesteps=total_timesteps,
    callback=eval_callback,
    tb_log_name="run"                  # TensorBoard é‡Œä¼šæ˜¾ç¤º run_1, run_2
)

# ==========================================
# ä¿å­˜æ”¶æ•›ç¬é—´çš„æœ€ç»ˆæ¨¡å‹
# ==========================================
model.save(f"{ckpt_dir}/final_model")
train_env.close()
eval_env.close()
print(f"è®­ç»ƒå®Œæˆã€‚TensorBoard logdir: {tb_log_dir}")